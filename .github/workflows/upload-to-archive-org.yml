name: Upload to Archive.org

on:
  workflow_dispatch:
    inputs:
      upload_method:
        description: 'Choose Upload Method'
        required: true
        type: choice
        options:
          - 'Direct URL File(s)'
          - 'Google Drive Folder'
      file_urls: # This input is conditional based on upload_method
        description: 'File URLs (space-separated, required for Direct URL File(s))'
        required: false # Set to false at workflow level, enforced by script
      gdrive_folder_id: # This input is conditional based on upload_method
        description: 'Google Drive Folder ID (e.g., 1wImUx1UkFVRDB-plqwoGo15blPgXD-Cn, required for Google Drive Folder)'
        required: false # Set to false at workflow level, enforced by script
      page_title:
        description: 'Page Title'
        required: true
      page_url:
        description: 'Page URL (optional, leave blank for default)'
        required: false
      description:
        description: 'Description'
        required: true
      subject_tags:
        description: 'Subject Tags (comma-separated)'
        required: true
      creator:
        description: 'Creator'
        required: false
      publish_date:
        description: 'Date (YYYY-MM-DD)'
        required: false
      collection_display:
        description: 'Collection'
        required: true
        type: choice
        options:
          - 'Community data'
          - 'Community texts'
          - 'Community audio'
          - 'Community movies'
          - 'Community software'
          - 'Community images'
      test_item:
        description: 'Is this a Test Item?'
        required: true
        type: choice
        options:
          - 'No'
          - 'Yes (will be removed after 30 days)'
      license_display:
        description: 'License'
        required: true
        type: choice
        options:
          - 'Leave license blank'
          - 'CC0 — “No Rights Reserved”'
          - 'Creative Commons Attribution-NoDerivs (No Remixing)'
          - 'Creative Commons Attribution (Allow Remixing)'
          - 'Creative Commons Attribution-ShareAlike (Allow Remixing, require Share-Alike)'
          - 'Creative Commons Attribution-NonCommercial (Allow Remixing, Prohibit Commercial Use)'
          - 'Creative Commons Attribution-NonCommercial-ShareAlike (Allow Remixing, require Share-Alike, Prohibit Commercial Use)'
          - 'Creative Commons Attribution-NonCommercial-NoDerivs (No Remixing, Prohibit Commercial Use)'
          - 'Public Domain'

jobs:
  upload_to_archiveorg:
    runs-on: ubuntu-latest
    steps:
    - name: Checkout repository
      uses: actions/checkout@v3

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.x'

    - name: Install Python dependencies
      run: |
        pip install internetarchive google-api-python-client google-auth-httplib2 google-auth-oauthlib

    - name: Configure internetarchive tool
      env:
        IA_ACCESS_KEY: ${{ secrets.IA_ACCESS_KEY }}
        IA_SECRET_KEY: ${{ secrets.IA_SECRET_KEY }}
      run: |
        echo "[s3]" > ~/.ia
        echo "access = $IA_ACCESS_KEY" >> ~/.ia
        echo "secret = $IA_SECRET_KEY" >> ~/.ia

    - name: Prepare Files for Upload
      id: prepare_files # Give this step an ID to output variables
      env:
        GCP_SA_KEY: ${{ secrets.GCP_SERVICE_ACCOUNT_KEY }}
        GDRIVE_FOLDER_ID: ${{ github.event.inputs.gdrive_folder_id }}
        FILE_URLS: ${{ github.event.inputs.file_urls }}
        UPLOAD_METHOD: ${{ github.event.inputs.upload_method }}
      run: |
        DOWNLOAD_DIR="gdrive_downloads" # Unified directory for downloaded files
        mkdir -p "$DOWNLOAD_DIR"
        
        # Array to hold local paths of files to upload
        FILES_TO_UPLOAD_ARRAY=()

        if [[ "$UPLOAD_METHOD" == "Direct URL File(s)" ]]; then
          echo "Selected upload method: Direct URL File(s)"
          if [[ -z "$FILE_URLS" ]]; then
            echo "Error: File URLs are required for 'Direct URL File(s)' upload method."
            exit 1
          fi

          IFS=' ' read -r -a URLS <<< "$FILE_URLS"
          for url in "${URLS[@]}"; do
            echo "Downloading: $url"
            wget -P "$DOWNLOAD_DIR" "$url"
            FILENAME=$(basename "$url")
            FILES_TO_UPLOAD_ARRAY+=("$DOWNLOAD_DIR/$FILENAME")
          done
        elif [[ "$UPLOAD_METHOD" == "Google Drive Folder" ]]; then
          echo "Selected upload method: Google Drive Folder"
          if [[ -z "$GDRIVE_FOLDER_ID" ]]; then
            echo "Error: Google Drive Folder ID is required for 'Google Drive Folder' upload method."
            exit 1
          fi
          if [[ -z "$GCP_SA_KEY" ]]; then
            echo "Error: GCP_SERVICE_ACCOUNT_KEY secret is missing. Required for Google Drive access."
            exit 1
          fi

          # Write the service account key to a file
          echo "$GCP_SA_KEY" > "$DOWNLOAD_DIR/service_account_key.json"

          python3 -c "
import os
import json
from google.oauth2 import service_account
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError
from googleapiclient.http import MediaIoBaseDownload
import io

FOLDER_ID = os.environ.get('GDRIVE_FOLDER_ID')
SERVICE_ACCOUNT_FILE = os.path.join(os.environ.get('DOWNLOAD_DIR'), 'service_account_key.json')
SCOPES = ['https://www.googleapis.com/auth/drive.readonly']
DOWNLOAD_DIR = os.environ.get('DOWNLOAD_DIR')
FILES_LIST_PATH = os.path.join(os.environ.get('GITHUB_WORKSPACE'), 'files_to_upload.txt')

try:
    credentials = service_account.Credentials.from_service_account_file(
        SERVICE_ACCOUNT_FILE, scopes=SCOPES
    )
    
    service = build('drive', 'v3', credentials=credentials)

    try:
        folder_metadata = service.files().get(fileId=FOLDER_ID, fields='name').execute()
        print(f'Attempting to download from Google Drive folder: {folder_metadata.get("name")}')
    except HttpError as error:
        print(f'Error retrieving folder metadata: {error}')
        print(f'Make sure the service account has Viewer access to folder ID: {FOLDER_ID}')
        exit(1)

    query = f\"'{FOLDER_ID}' in parents and trashed = false\"
    results = service.files().list(
        q=query,
        fields='files(id, name, mimeType, size)',
        supportsAllDrives=True,
        includeItemsFromAllDrives=True
    ).execute()
    items = results.get('files', [])

    if not items:
        print('No files found in the folder.')
    else:
        print(f'Found {len(items)} files.')
        downloaded_files_count = 0
        with open(FILES_LIST_PATH, 'a') as f_list: # Open in append mode
            for item in items:
                file_id = item['id']
                file_name = item['name']
                mime_type = item['mimeType']
                
                print(f'Downloading: {file_name} (ID: {file_id}, MimeType: {mime_type})')

                request = service.files().get_media(fileId=file_id)
                
                output_file_name = file_name
                # Special handling for Google Docs/Sheets/Slides (export as PDF, etc.)
                if 'google-apps' in mime_type:
                    if 'document' in mime_type:
                        request = service.files().export_media(fileId=file_id, mimeType='application/pdf')
                        output_file_name += '.pdf'
                    elif 'spreadsheet' in mime_type:
                        request = service.files().export_media(fileId=file_id, mimeType='application/vnd.openxmlformats-officedocument.spreadsheetml.sheet')
                        output_file_name += '.xlsx'
                    elif 'presentation' in mime_type:
                        request = service.files().export_media(fileId=file_id, mimeType='application/pdf')
                        output_file_name += '.pdf'
                    else:
                        print(f'Warning: Skipping Google Workspace file {file_name} with unhandled mimeType: {mime_type}')
                        continue
                
                full_path = os.path.join(DOWNLOAD_DIR, output_file_name)
                fh = io.FileIO(full_path, 'wb')
                downloader = MediaIoBaseDownload(fh, request)
                done = False
                while done is False:
                    status, done = downloader.next_chunk()
                    # print(f'Download progress for {file_name}: {int(status.progress() * 100)}%', end='\r')
                print(f'Successfully downloaded: {file_name}')
                f_list.write(f'{full_path}\n') # Write full path to file
                downloaded_files_count += 1
            print(f'Finished downloading {downloaded_files_count} files.')

except HttpError as error:
    print(f'An API error occurred: {error}')
    print('Please ensure:')
    print('1. The Google Drive API is enabled in your Google Cloud Project.')
    print('2. Your GCP_SERVICE_ACCOUNT_KEY secret contains the correct JSON content.')
    print('3. The Service Account email has "Viewer" access to the Google Drive folder.')
    exit(1)
except Exception as e:
    print(f'An unexpected error occurred: {e}')
    exit(1)
          "
          # Find all downloaded files in the temp directory and pass their paths
          # The Python script now writes directly to files_to_upload.txt
          # find "$DOWNLOAD_DIR" -maxdepth 1 -type f -print0 | xargs -0 -I {} echo "{}" >> files_to_upload.txt
        else
          echo "Error: Unknown upload method selected: $UPLOAD_METHOD"
          exit 1
        fi

        # Store the list of files to upload in an output variable
        # This makes the paths available to subsequent steps
        if [ ${#FILES_TO_UPLOAD_ARRAY[@]} -eq 0 ] && [ "$UPLOAD_METHOD" == "Direct URL File(s)" ]; then
            echo "No files specified for Direct URL File(s) upload."
            echo "files_list=" >> "$GITHUB_OUTPUT" # Output empty list
        else
            # For GDrive, the Python script directly writes to files_to_upload.txt
            # For Direct URL, we populate the array and then write it
            if [[ "$UPLOAD_METHOD" == "Direct URL File(s)" ]]; then
                printf "%s\n" "${FILES_TO_UPLOAD_ARRAY[@]}" > files_to_upload.txt
            fi
            echo "files_list=$(cat files_to_upload.txt | xargs echo)" >> "$GITHUB_OUTPUT"
        fi


    - name: Upload files to Archive.org
      if: ${{ success() && steps.prepare_files.outputs.files_list != '' }} # Only run if prepare_files succeeded and found files
      run: |
        IDENTIFIER="${{ github.event.inputs.page_url || '' }}"
        if [ -z "$IDENTIFIER" ]; then
          IDENTIFIER=$(echo "${{ github.event.inputs.page_title }}" | tr ' ' '-' | tr '[:upper:]' '[:lower:]' | sed 's/[^a-z0-9_.-]//g')
        fi

        # --- Handle License Mapping ---
        declare -A LICENSE_MAP
        LICENSE_MAP["Leave license blank"]=""
        LICENSE_MAP["CC0 — “No Rights Reserved”"]="http://creativecommons.org/publicdomain/zero/1.0/"
        LICENSE_MAP["Creative Commons Attribution-NoDerivs (No Remixing)"]="http://creativecommons.org/licenses/by-nd/4.0/"
        LICENSE_MAP["Creative Commons Attribution (Allow Remixing)"]="http://creativecommons.org/licenses/by/4.0/"
        LICENSE_MAP["Creative Commons Attribution-ShareAlike (Allow Remixing, require Share-Alike)"]="http://creativecommons.org/licenses/by-sa/4.0/"
        LICENSE_MAP["Creative Commons Attribution-NonCommercial (Allow Remixing, Prohibit Commercial Use)"]="http://creativecommons.org/licenses/by-nc/4.0/"
        LICENSE_MAP["Creative Commons Attribution-NonCommercial-ShareAlike (Allow Remixing, require Share-Alike, Prohibit Commercial Use)"]="http://creativecommons.org/licenses/by-nc-sa/4.0/"
        LICENSE_MAP["Creative Commons Attribution-NonCommercial-NoDerivs (No Remixing, Prohibit Commercial Use)"]="http://creativecommons.org/licenses/by-nc-nd/4.0/"
        LICENSE_MAP["Public Domain"]="http://creativecommons.org/publicdomain/mark/1.0/"

        SELECTED_LICENSE_DISPLAY="${{ github.event.inputs.license_display }}"
        LICENSE_URL="${LICENSE_MAP["$SELECTED_LICENSE_DISPLAY"]}"

        # --- Handle Collection Mapping ---
        declare -A COLLECTION_MAP
        COLLECTION_MAP["Community data"]="opensource_media"
        COLLECTION_MAP["Community texts"]="opensource_texts"
        COLLECTION_MAP["Community audio"]="opensource_audio"
        COLLECTION_MAP["Community movies"]="opensource_movies"
        COLLECTION_MAP["Community software"]="opensource_software"
        COLLECTION_MAP["Community images"]="opensource_image"

        SELECTED_COLLECTION_DISPLAY="${{ github.event.inputs.collection_display }}"
        COLLECTION_VALUE="${COLLECTION_MAP["$SELECTED_COLLECTION_DISPLAY"]}"

        METADATA=(
          "--metadata=title:${{ github.event.inputs.page_title }}"
          "--metadata=description:${{ github.event.inputs.description }}"
          "--metadata=creator:${{ github.event.inputs.creator }}"
          "--metadata=date:${{ github.event.inputs.publish_date }}"
          "--metadata=subject:${{ github.event.inputs.subject_tags }}"
          "--metadata=collection:$COLLECTION_VALUE"
        )
        
        if [[ -n "$LICENSE_URL" ]]; then
          METADATA+=("--metadata=licenseurl:$LICENSE_URL")
        fi

        if [[ "${{ github.event.inputs.test_item }}" == "Yes (will be removed after 30 days)" ]]; then
          METADATA+=("--metadata=test_item:true")
        fi

        # Get the list of files from the output of the previous step
        FILES_TO_UPLOAD=(${{ steps.prepare_files.outputs.files_list }})

        if [ ${#FILES_TO_UPLOAD[@]} -eq 0 ]; then
          echo "No files found to upload. Skipping ia upload."
          exit 0
        fi

        ia upload "$IDENTIFIER" "${FILES_TO_UPLOAD[@]}" "${METADATA[@]}"