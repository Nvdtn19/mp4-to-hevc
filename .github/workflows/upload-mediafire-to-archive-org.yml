name: Download with Embedded Script and Upload to Archive.org

on:
  workflow_dispatch:
    inputs:
      mediafire_urls:
        description: 'One or more space-separated MediaFire URLs (file or folder)'
        required: true
      archive_title:
        description: 'Title for the Archive.org item'
        required: true
      archive_page_url_id:
        description: 'Page URL ID for the Archive.org item (auto-generated if empty)'
        required: false
      archive_description:
        description: 'Description for the Archive.org item'
        required: false
        default: 'Archived from MediaFire'
      archive_subject_tags:
        description: 'Comma-separated subject tags for the Archive.org item'
        required: false
      archive_collection_id:
        description: 'Archive.org collection ID'
        required: false
        default: 'opensource_media'
      is_test_item:
        description: 'Set to "true" for a test item upload'
        required: false
        default: 'false'

jobs:
  download-and-upload:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'

      - name: Install Dependencies
        run: |
          python -m pip install --upgrade pip
          pip install bs4 requests tqdm internetarchive

      - name: Create Downloader Script
        run: |
          cat <<'EOF' > mediafire-dl.py
          #!/usr/bin/python

          import requests
          from bs4 import BeautifulSoup
          from tqdm import tqdm
          import sys
          import os
          import errno
          import time

          chunk_size = 1024 # 32KB
          os_path_separator = os.path.sep

          def make_sure_path_exists(path):
              try:
                  os.makedirs(path)
              except OSError as exception:
                  if exception.errno != errno.EEXIST:
                      raise

          class MediafireDownloader:
              dl_file_name = ''
              dl_file_full_path = ''
              dl_total_file_size = 0
              dl_existing_file_size = 0

              dl_page_url = ''
              dl_file_url = ''

              def __init__(self):
                  pass

              def get_subfolders_from_folder(self, folder_key, parent):
                  api_call_link = "http://mediafire.com/api/1.5/folder/get_content.php?folder_key=" + folder_key + \
                                  "&content_type=folders&chunk_size=1000&response_format=json"
                  resp_json = requests.get(api_call_link).json()
                  subfolders_in_folder = resp_json['response']['folder_content']['folders']

                  if subfolders_in_folder == []:
                      # No subfolders >> don't request it again
                      return False

                  for subfolder in subfolders_in_folder:
                      subfolder_name = subfolder['name']
                      subfolder_parent = parent + subfolder_name + os_path_separator
                      subfolder_key = subfolder['folderkey']

                      print('----------------------------')
                      print('Downloading folder: ' + subfolder_parent)
                      self.download_folder(subfolder_key, subfolder_parent)


              def download_files_in_folder(self, folder_key, parent):
                  api_call_link = "http://mediafire.com/api/1.5/folder/get_content.php?folder_key=" + folder_key \
                                  + "&content_type=files&chunk_size=1000&response_format=json"
                  resp_json = requests.get(api_call_link).json()
                  files_in_folder = resp_json['response']['folder_content']['files']

                  for file in files_in_folder:
                      file_page_url = file['links']['normal_download']
                      self.download_file(file_page_url, parent)


              def download_folder(self, folder_key, parent):
                  # Get files in current folder
                  self.download_files_in_folder(folder_key, parent)

                  # Get files in subfolders
                  self.get_subfolders_from_folder(folder_key, parent)

              def download(self, mediafire_link):
                  if "mediafire.com/folder/" in mediafire_link:
                      folder_slug_start = mediafire_link.find("mediafire.com/folder/") + len("mediafire.com/folder/")
                      hash_pos = mediafire_link.rfind('#')
                      if hash_pos != -1 and hash_pos > folder_slug_start:
                          folder_key = mediafire_link[hash_pos+1:]
                      else:
                          folder_slug_end = mediafire_link.find('/', folder_slug_start)
                          if folder_slug_end == -1:
                              folder_slug_end = len(mediafire_link)
                          folder_key = mediafire_link[folder_slug_start:folder_slug_end]
                      self.download_folder(folder_key, '')
                  else:
                      self.download_file(mediafire_link, '')

              def download_file(self, mediafire_file_link, parent, file_name=''):
                  cwd = os.getcwd()
                  self.dl_page_url = mediafire_file_link
                  print('----------------')
                  print('Getting link from ' + self.dl_page_url)

                  r_download_page = requests.get(self.dl_page_url)
                  soup_download_page = BeautifulSoup(r_download_page.text, 'lxml')
                  download_link_element = soup_download_page.select_one('.download_link a.input')
                  
                  if not download_link_element:
                      print(f"Could not find download button for {mediafire_file_link}. Skipping.")
                      return

                  self.dl_file_url = download_link_element.get('href', '')
                  if not self.dl_file_url.startswith('http'):
                      print(f"Found invalid download URL: {self.dl_file_url}. Skipping.")
                      return

                  header_request = requests.head(self.dl_file_url, allow_redirects=True)
                  self.dl_total_file_size = int(header_request.headers.get('Content-Length', 0))
                  
                  cd = header_request.headers.get('content-disposition', '')
                  file_name_key = 'filename="'
                  fn_start = cd.find(file_name_key)
                  if fn_start != -1:
                      fn_start += len(file_name_key)
                      fn_end = cd.find('"', fn_start)
                      self.dl_file_name = cd[fn_start:fn_end]
                  else:
                      self.dl_file_name = os.path.basename(self.dl_file_url.split('?')[0])

                  ss = os.path.join(cwd, parent)
                  make_sure_path_exists(ss)
                  self.dl_file_full_path = os.path.join(cwd, parent, self.dl_file_name)

                  if os.path.exists(self.dl_file_full_path) and os.path.getsize(self.dl_file_full_path) == self.dl_total_file_size:
                      print(f'File "{os.path.join(parent, self.dl_file_name)}" already downloaded.')
                      return

                  print(f'Downloading "{self.dl_file_full_path}".')
                  with requests.get(self.dl_file_url, stream=True) as r:
                      r.raise_for_status()
                      with open(self.dl_file_full_path, 'wb') as f:
                          with tqdm(total=self.dl_total_file_size, unit='B', unit_scale=True, unit_divisor=1024, desc=self.dl_file_name) as pbar:
                              for chunk in r.iter_content(chunk_size=chunk_size):
                                  f.write(chunk)
                                  pbar.update(len(chunk))
                  print(f'Finished Downloading "{self.dl_file_full_path}".')

          def main():
              if len(sys.argv) < 2:
                  print('Usage: mediafire-dl.py mediafire_link_1 mediafire_link_2 ...')
                  sys.exit(1)

              mf = MediafireDownloader()
              for mediafire_link in sys.argv[1:]:
                  mf.download(mediafire_link)

          if __name__ == "__main__":
              main()
          EOF

      - name: Download Files using generated script
        run: python mediafire-dl.py ${{ github.event.inputs.mediafire_urls }}

      - name: Create Archive.org Config File
        run: |
          mkdir -p ~/.config/internetarchive
          cat <<EOF > ~/.config/internetarchive/ia.ini
          [s3]
          access = ${{ secrets.IA_ACCESS_KEY }}
          secret = ${{ secrets.IA_SECRET_KEY }}
          EOF

      - name: Set Archive.org identifier
        id: set_identifier
        run: |
          if [ -z "${{ github.event.inputs.archive_page_url_id }}" ]; then
            echo "identifier=$(date +%s%N)" >> $GITHUB_OUTPUT
          else
            echo "identifier=${{ github.event.inputs.archive_page_url_id }}" >> $GITHUB_OUTPUT
          fi

      - name: Prepare files for upload
        id: prep_files
        run: |
          UPLOAD_ITEMS=$(ls -A | grep -vE '^\.git|^\.github|^mediafire-dl\.py')
          if [ -z "$UPLOAD_ITEMS" ]; then
            echo "No new files or folders found to upload."
            exit 1
          fi
          echo "items_to_upload=$UPLOAD_ITEMS" >> $GITHUB_OUTPUT
          echo "Uploading the following items:"
          echo "$UPLOAD_ITEMS"

      - name: Upload to Archive.org
        run: |
          COLLECTION="${{ github.event.inputs.archive_collection_id }}"
          if [ "${{ github.event.inputs.is_test_item }}" = "true" ]; then
            COLLECTION="test_collection"
          fi
          
          ia upload ${{ steps.set_identifier.outputs.identifier }} ${{ steps.prep_files.outputs.items_to_upload }} \
            --metadata="title:${{ github.event.inputs.archive_title }}" \
            --metadata="description:${{ github.event.inputs.archive_description }}" \
            --metadata="subject:${{ github.event.inputs.archive_subject_tags }}" \
            --metadata="collection:${COLLECTION}"